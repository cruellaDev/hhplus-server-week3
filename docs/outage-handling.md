# 콘서트 예약 시스템 장애 대응 및 예방 방안 보고서

## 1. 시스템 개요

콘서트 예약 시스템은 사용자가 콘서트 티켓을 예약하고 결제를 처리하는 시스템이다. 시스템의 주요 컴포넌트는 다음과 같다:

- **결제 데이터 생성**
- **티켓 발급 처리**
- **포인트 차감**
- **토큰 만료**
- **Outbox Pattern을 사용한 Kafka 메시지 전송**
- **카카오 알림톡 전송**

이 시스템은 MySQL 데이터베이스를 사용하며, Application Event를 통해 결제 요청을 처리한다. 트랜잭션 관리를 위해 `@TransactionalEventListener`를 활용하고 있으며, 데이터베이스에 반드시 반영되어야 하는 작업은 `beforeCommit` 단계에서 처리하고, 외부 시스템과의 연동은 `afterCommit` 단계에서 처리한다.

## 2. 시스템에서 발생할 수 있는 장애 및 대응책

### 2.1 결제 데이터 생성 장애
- **원인**: 네트워크 문제, 서버 문제 등으로 인해 결제 데이터 생성 중 장애가 발생할 수 있다.
- **대응책**:
    - **자동 롤백**: 트랜잭션이 롤백되어 데이터베이스 상태가 일관되게 유지된다.
    - **오류 로깅 및 모니터링**: 오류를 기록하고 모니터링을 통해 신속히 대응한다.
    - **구체적인 재시도 로직**:
        - **지수적 백오프 적용**: 결제 실패 시 지수적으로 증가하는 대기 시간을 두고 최대 5회까지 재시도한다.
        - **상태 기반 재시도**: 네트워크 오류(예: 타임아웃) 시에만 재시도하고, 클라이언트 오류(예: 4xx 응답) 시에는 재시도하지 않는다.
        - **결제 상태 확인 후 재시도**: 재시도 전에 결제가 이미 완료되었는지 확인하여 중복 결제를 방지한다.
    - **잠재적 장애**: 결제 처리 중 예상치 못한 예외가 발생할 수 있으며(`Unhandled Exception`), 비효율적인 데이터 처리로 인해 시스템 리소스가 부족해질 수 있다(`Lack of Resource`).

### 2.2 티켓 발급 처리 장애
- **원인**: 서버 과부하, 데이터베이스 문제 등으로 인해 티켓 발급 중 장애가 발생할 수 있다.
- **대응책**:
    - **트랜잭션 롤백**: 장애 발생 시 트랜잭션을 롤백하여 결제를 취소한다.
    - **구체적인 재시도 로직**:
        - **지수적 백오프 적용**: 티켓 발급 실패 시 지수적 백오프를 적용하여 최대 3회까지 재시도한다.
        - **예약 상태 확인 후 재시도**: 재시도 전에 티켓이 이미 발급되었는지 확인하여 중복 발급을 방지한다.
        - **서킷 브레이커 적용**: 발급 요청 실패가 연속으로 발생할 경우 서킷 브레이커를 통해 일정 시간 동안 재시도를 차단한다.
    - **잠재적 장애**:
        - **메모리 누수 및 OOM**: 티켓 발급 과정에서 메모리 사용량이 급증하거나 메모리 누수가 발생할 수 있다(`Lack of Resource`).
        - **처리되지 않은 예외**: 데이터베이스 접근 오류나 네트워크 문제로 인해 예외가 발생하고, 적절히 처리되지 않으면 앱 크래시로 이어질 수 있다(`Unhandled Exception`).

### 2.3 포인트 차감 장애
- **원인**: 데이터베이스 문제, 네트워크 장애 등으로 인해 포인트 차감 중 장애가 발생할 수 있다.
- **대응책**:
    - **포인트 차감 트랜잭션화**: 포인트 차감을 트랜잭션 내에서 처리하여 일관성을 보장한다.
    - **구체적인 재시도 로직**:
        - **트랜잭션 롤백 및 재시도**: 차감 실패 시 트랜잭션을 롤백하고 지수적 백오프를 적용하여 최대 3회 재시도한다.
        - **일관성 유지 검증**: 재시도 전에 포인트 차감이 일부 이루어졌는지 검증하여 데이터 일관성을 유지한다.
    - **보상 트랜잭션 적용**: 만약 재시도가 모두 실패할 경우, 이미 차감된 포인트를 복구하는 보상 트랜잭션을 실행한다.
    - **잠재적 장애**:
        - **메모리 누수 및 OOM**: 포인트 차감 과정에서 비효율적인 메모리 사용으로 OOM 오류가 발생할 수 있다(`Lack of Resource`).
        - **예외 처리 부족**: 데이터베이스 또는 네트워크 문제로 인한 예외가 적절히 처리되지 않으면 시스템이 크래시할 수 있다(`Unhandled Exception`).
        - **응답 지연**: 데이터베이스 쿼리가 비효율적이거나 인덱스가 최적화되지 않아 응답 지연이 발생할 수 있다(`Slow Query, I/O`).

### 2.4 토큰 만료 처리 장애
- **원인**: 토큰 만료 처리 중 네트워크 장애나 서버 오류가 발생할 수 있다.
- **대응책**:
    - **토큰 검증 강화**: 결제 시 토큰 유효성을 재검증한다.
    - **구체적인 재시도 로직**:
        - **백오프 전략 적용**: 토큰 만료 실패 시 지수적 백오프를 적용하여 최대 5회까지 재시도한다.
        - **만료 확인 후 재시도**: 재시도 전에 토큰이 이미 만료되었는지 확인하여 중복 만료를 방지한다.
        - **백그라운드 프로세싱**: 만료 작업을 백그라운드에서 처리하여 주 작업에 영향을 주지 않도록 한다.
    - **잠재적 장애**:
        - **처리되지 않은 예외**: 외부 시스템과의 연동 중 예외가 발생하고, 이를 적절히 처리하지 않으면 시스템이 크래시할 수 있다(`Unhandled Exception`).
        - **응답 지연**: 외부 시스템과의 통신이 느려지면 토큰 만료 처리 시간이 길어질 수 있다(`Slow Query, I/O`).

### 2.5 Outbox Message 전송 장애
- **원인**: Kafka 브로커 장애, 네트워크 문제 등으로 인해 메시지 전송이 실패할 수 있다.
- **대응책**:
    - **구체적인 재시도 로직**:
        - **지수적 백오프와 큐 기반 재시도**: 메시지 전송 실패 시 지수적 백오프를 적용하고, 최대 5회 실패 시 큐에 저장하여 주기적으로 재시도한다.
        - **최대 재시도 횟수 설정**: 재시도에도 실패할 경우 메시지를 Dead Letter Queue(DLQ)에 저장하여 수동으로 처리한다.
        - **메시지 상태 확인 후 재시도**: 재시도 전에 메시지가 이미 처리되었는지 확인하여 중복 처리를 방지한다.
    - **잠재적 장애**:
        - **메모리 누수 및 OOM**: 메시지 큐에 과도한 메시지가 쌓여 메모리 부족으로 시스템이 중단될 수 있다(`Lack of Resource`).
        - **응답 지연**: Kafka와의 통신에서 네트워크 지연이 발생할 경우, 메시지 전송이 지연될 수 있다(`Slow Query, I/O`).

### 2.6 카카오 알림톡 전송 장애
- **원인**: 카카오 알림톡 API 호출 실패, 네트워크 장애 등이 발생할 수 있다.
- **대응책**:
    - **재전송 로직**: 전송 실패 시 지수적 백오프를 적용하여 재시도한다.
    - **백업 알림 채널**: SMS 등 다른 알림 수단을 통해 결제 완료 사실을 사용자에게 전달한다.
    - **잠재적 장애**:
        - **메모리 누수 및 OOM**: 대량의 알림 전송 시 메모리 누수로 인해 시스템이 비정상 종료될 수 있다(`Lack of Resource`).
        - **처리되지 않은 예외**: API 호출 중 예외가 발생하고, 이를 적절히 처리하지 않으면 시스템이 크래시할 수 있다(`Unhandled Exception`).

## 3. 장애 대응 숏텀, 미드텀, 롱텀 방책

### 3.1 숏텀 (Short-term) 대응 방책
- **모니터링 및 알림 시스템 강화**: 실시간 모니터링을 도입하고, 장애 발생 시 운영팀에 즉시 알림을 보낸다.
- **재시도 로직 구현**: 결제, 메시지 전송 등 주요 프로세스에 재시도 로직을 추가한다.
- **장애 복구 매뉴얼 작성**: 장애 발생 시 대응 절차를 정리한 매뉴얼을 작성한다.

### 3.2 미드텀 (Mid-term) 대응 방책
- **데이터 일관성 검증 도구 도입**: DB와 외부 시스템 간의 데이터 일관성 검증 도구를 도입한다.
- **SAGA 패턴 도입**: 분산 트랜잭션 관리 패턴을 도입한다.
- **비동기 처리 전환**: 트랜잭션 범위 외 작업을 비동기 처리로 전환한다.
- **장애 복구 자동화**: 장애 발생 시 자동으로 복구 작업을 수행하는 시스템을 구축한다.

### 3.3 롱텀 (Long-term) 대응 방책
- **마이크로서비스 아키텍처 도입**: 시스템을 독립적인 서비스로 분리하여 확장성을 확보한다.
- **로드 밸런싱 및 확장성 강화**: 자동 확장 및 로드 밸런싱을 도입한다.
- **AI 기반 장애 예측**: 인공지능 기반의 예측 분석을 통해 잠재적인 장애를 사전에 예측한다.

## 4. DB, Kafka, 외부 API로 인한 장애 및 대응책

### 4.1 데이터베이스 (DB) 관련 장애 및 대응책
- **데이터베이스 연결 장애**: 연결 풀 관리 최적화, 백업 DB 사용, DB 재시도 로직을 구현한다.
- **데이터베이스 성능 저하**: 쿼리 최적화, 데이터베이스 샤딩, 캐싱을 도입한다.
- **데이터 손상 및 일관성 문제**: 트랜잭션 로그 백업, 데이터베이스 복제 및 동기화, 정기적인 데이터 검증을 실시한다.

### 4.2 Kafka 관련 장애 및 대응책
- **메시지 손실 및 중복**: Idempotency 구현, 메시지 ACK 설정, DLQ (Dead Letter Queue)를 도입한다.
- **Kafka 브로커 장애**: 멀티 브로커 설정, Zookeeper 모니터링, 자동 복구 스크립트를 실행한다.
- **메시지 처리 지연**: 파티션 확장, 메시지 처리 최적화, 모니터링 및 알림 설정을 진행한다.

### 4.3 외부 API 관련 장애 및 대응책

- **외부 API 호출 실패**
    - **원인**: 외부 API 서비스 다운타임, 네트워크 문제로 인해 API 호출이 실패할 수 있다.
    - **대응책**:
        - **서킷 브레이커 패턴 도입**: 외부 API 호출 실패가 일정 횟수 이상 발생하면 서킷을 열고, 일정 시간 후 다시 닫아 API 호출을 재개한다. 이를 통해 시스템이 불필요한 호출로 인해 과부하에 걸리지 않도록 한다.
          <details>
          <summary>서킷 브레이커의 장점</summary>

            - 시스템 보호: 외부 API의 장애가 발생해도 내부 시스템에 미치는 영향을 최소화할 수 있다.
            - 빠른 장애 탐지: 장애 발생 후 일정 시간 동안 추가적인 실패 시도를 방지하여 장애 탐지가 빨라진다.
            - 대체 동작 수행: 서킷이 열린 상태에서 대체 동작을 수행해 사용자에게 일관된 경험을 제공한다.

          </details>
        - **지수적 백오프 전략**: 재시도 시 각 재시도 간의 대기 시간을 지수적으로 증가시켜 서버 부하를 줄이고 네트워크 문제를 극복한다.
        - **최대 재시도 횟수 설정**: 최대 재시도 횟수를 설정하여 무한 반복을 방지하고 시스템 리소스 낭비를 줄인다.
        - **랜덤 지연 추가**: 동시다발적인 재시도를 방지하기 위해 각 재시도 간의 지연 시간을 랜덤하게 추가한다.
        - **상태 기반 재시도**: 서버 오류(5xx) 시에만 재시도하고, 클라이언트 오류(4xx)인 경우 재시도하지 않는다.
        - **큐 기반 재시도**: 재시도 요청을 큐에 넣고 일정 주기마다 처리하여 부하를 분산한다.

- **API 응답 지연**
    - **원인**: 외부 API의 응답 지연으로 인해 시스템 성능이 저하될 수 있다.
    - **대응책**:
        - **서킷 브레이커 패턴 도입**: 응답 지연이 계속될 경우 서킷 브레이커를 통해 호출을 차단하고, 대체 방안을 실행한다.
        - **타임아웃 설정**: 외부 API 호출 시 적절한 타임아웃을 설정하여 지연으로 인한 시스템 대기 시간을 줄인다.
        - **비동기 호출 전환**: 외부 API 호출을 비동기 처리로 전환하여 응답 지연 시에도 시스템의 다른 기능이 원활하게 동작하도록 한다.
        - **캐싱 도입**: 외부 API에서 자주 조회하는 데이터를 캐싱하여 API 호출 횟수를 줄이고 성능을 향상시킨다.

- **API 요청 제한 초과**
    - **원인**: 외부 API의 Rate Limit(요청 제한)을 초과하여 더 이상 요청을 처리할 수 없게 될 수 있다.
    - **대응책**:
        - **서킷 브레이커 패턴 도입**: Rate Limit 초과 시 서킷을 열어 호출을 잠시 차단하고, 대체 방안을 적용한다.
        - **Rate Limiting 관리**: 외부 API의 요청 제한을 고려하여 API 호출 빈도를 조절한다.
        - **콜랩스 요청 처리**: 같은 요청을 병합하여 한 번만 API를 호출하도록 하여 요청 수를 줄인다.
        - **API 요청 분산**: 요청을 분산하여 제한을 초과하지 않도록 관리하고, 주기적으로 요청할 수 있도록 스케줄러를 활용한다.

## 5. Redis 기반 대기열 시스템 적용 계획 및 대응책

### 5.1 Redis 서버 다운 및 연결 장애
- **원인**: Redis 서버 장애, 네트워크 문제로 인한 연결 장애가 발생할 수 있다.
- **대응책**:
    - **Redis 클러스터 설정**: Redis를 클러스터링하여 고가용성을 확보하고, 장애 발생 시 자동으로 다른 노드로 페일오버(Failover)되도록 설정한다.
    - **Sentinel 도입**: Redis Sentinel을 사용하여 Redis 인스턴스의 가용성을 모니터링하고, 장애 시 자동으로 마스터를 전환한다.
    - **재시도 로직**: Redis 연결에 실패 시 일정 시간 후 자동 재시도 로직을 구현한다.
    - **잠재적 장애**:
        - **메모리 누수 및 OOM**: Redis에서 메모리 누수나 과도한 메모리 사용으로 인해 OOM 오류가 발생할 수 있다(`Lack of Resource`).
        - **응답 지연**: Redis에 비효율적으로 접근하거나 데이터 구조가 최적화되지 않아 응답 지연이 발생할 수 있다(`Slow Query, I/O`).

### 5.2 데이터 일관성 문제
- **원인**: 여러 클라이언트의 동시 접근으로 인해 데이터 경합이 발생할 수 있다.
- **대응책**:
    - **분산 락 사용**: Redis의 `SETNX` 또는 `Redlock`을 사용하여 동시성 제어를 강화한다.
    - **트랜잭션 사용**: Redis의 `MULTI`와 `EXEC` 명령어로 원자적 연산을 수행하여 데이터 일관성을 보장한다.
    - **TTL 설정**: 토큰 만료 시점에 대해 TTL(Time To Live)을 명확히 설정하여 자동 만료를 보장한다.

### 5.3 메모리 부족 문제
- **원인**: Redis는 인메모리 데이터베이스이므로 메모리 부족 시 성능 저하 및 데이터 유실이 발생할 수 있다.
- **대응책**:
    - **메모리 관리 정책 설정**: Redis의 메모리 관리 정책(예: LRU, LFU)을 설정하여 필요 없는 데이터를 자동으로 삭제한다.
    - **데이터 압축**: 저장하는 데이터 크기를 줄이기 위해 압축을 적용하거나 데이터 구조를 최적화한다.
    - **모니터링 및 경고**: Redis 메모리 사용량을 실시간 모니터링하고, 메모리 부족 시 경고 알림을 발송한다.

### 5.4 Redis 데이터 영속성 문제
- **원인**: Redis는 인메모리 스토어이므로, 비정상적인 종료 시 데이터 유실이 발생할 수 있다.
- **대응책**:
    - **AOF(Append-Only File) 사용**: 데이터 변경 사항을 디스크에 순차적으로 기록하는 AOF를 활성화하여 데이터 복구 가능성을 확보한다.
    - **RDB 스냅샷**: 주기적인 RDB 스냅샷을 통해 데이터베이스 상태를 저장하고, 장애 시 해당 스냅샷을 통해 복구한다.
    - **복제 설정**: 마스터-슬레이브 구조로 복제를 설정하여 마스터 서버 장애 시에도 슬레이브 서버에서 데이터 복구가 가능하도록 한다.

### 5.5 토큰 만료 처리 지연
- **원인**: Redis 부하가 높아질 경우, 대기열 처리와 토큰 만료 처리 간 경합이 발생할 수 있다.
- **대응책**:
    - **백그라운드 작업 처리**: 토큰 만료를 별도의 백그라운드 작업으로 처리하여 대기열의 토큰 발급과 분리된 스레드에서 수행한다.
    - **Lua 스크립트 사용**: Redis의 Lua 스크립트를 사용하여 토큰 발급과 만료를 원자적으로 처리해 성능과 일관성을 확보한다.
    - **우선순위 큐 도입**: Redis에서 우선순위 큐를 구현하여, 만료가 가까운 토큰을 우선 처리하도록 큐의 순서를 조정한다.

## 6. 보상 트랜잭션의 적용

보상 트랜잭션은 시스템에서 발생한 작업을 취소하거나 원래 상태로 되돌리는 작업으로, 재시도 로직과 함께 사용할 수 있다. 다음과 같은 경우에 보상 트랜잭션이 효과적일 수 있다:

- **분산 트랜잭션 관리**: 여러 시스템 간의 작업이 성공해야 전체 트랜잭션이 성공으로 간주되는 경우, 예를 들어 결제는 성공했지만 티켓 발급이 실패한 경우, 결제를 취소하는 보상 트랜잭션이 필요할 수 있다.
- **비가역적 작업 처리**: 재시도가 실패하거나 더 이상 유효하지 않은 경우, 보상 트랜잭션을 사용하여 작업을 취소하거나 롤백하여 시스템 일관성을 유지한다.

보상 트랜잭션은 재시도 로직을 보완하며, 복잡한 시스템에서의 일관성 유지에 중요한 역할을 한다. 재시도 후에도 작업이 성공하지 않는 경우, 보상 트랜잭션을 통해 이미 완료된 작업을 되돌려 시스템을 원상태로 복구할 수 있다.

## 결론

본 보고서는 콘서트 예약 시스템에서 발생할 수 있는 주요 장애를 분석하고, 이에 대한 재시도 로직과 보상 트랜잭션을 포함한 대응책을 제시하였다. 구체적인 재시도 전략과 보상 트랜잭션의 조합을 통해 시스템의 안정성과 신뢰성을 높일 수 있으며, Redis 기반의 대기열 시스템에 대한 적용 계획과 대응책도 포함하여 시스템의 장기적인 성능과 안정성을 보장할 수 있도록 설계하였다.
